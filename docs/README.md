# ğŸ• ClassificaÃ§Ã£o de RaÃ§as de Cachorros com Deep Learning

**Trabalho Final de CSN - Machine Learning**  
**Autor:** Luis  
**Data:** 26/11/2025

---

## ğŸ“‹ DescriÃ§Ã£o do Projeto

Este projeto implementa um sistema de classificaÃ§Ã£o de raÃ§as de cachorros usando **Transfer Learning** com **Convolutional Neural Networks (CNN)**. O modelo Ã© capaz de identificar mais de 70 raÃ§as diferentes de cachorros a partir de imagens.

### ğŸ¯ Objetivos

- Implementar e treinar um modelo de classificaÃ§Ã£o de imagens usando CNNs
- Aplicar tÃ©cnicas de Transfer Learning com arquitetura moderna (EfficientNetB0)
- Utilizar Data Augmentation para melhorar a generalizaÃ§Ã£o
- Realizar anÃ¡lise exploratÃ³ria detalhada dos dados
- Analisar erros de classificaÃ§Ã£o e interpretar resultados

---

## ğŸ“Š Dataset

O dataset utilizado contÃ©m imagens de **70+ raÃ§as de cachorros**, organizado em:
- **Train**: Conjunto de treinamento (~7000+ imagens)
- **Validation**: Conjunto de validaÃ§Ã£o (~1000+ imagens)  
- **Test**: Conjunto de teste (~1000+ imagens)

Estrutura do dataset:
```
archive/
â”œâ”€â”€ dogs.csv                    # Metadados das imagens
â”œâ”€â”€ train/                      # Imagens de treinamento
â”‚   â”œâ”€â”€ Afghan/
â”‚   â”œâ”€â”€ Labrador/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ valid/                      # Imagens de validaÃ§Ã£o
â””â”€â”€ test/                       # Imagens de teste
```

---

## ğŸ—ï¸ Arquitetura do Modelo

### Transfer Learning com EfficientNetB0

O modelo utiliza **EfficientNetB0** prÃ©-treinado no ImageNet como base:

```
Input (224x224x3)
    â†“
EfficientNetB0 (congelado)
    â†“
GlobalAveragePooling2D
    â†“
Dense(512, ReLU) + Dropout(0.5)
    â†“
Dense(256, ReLU) + Dropout(0.3)
    â†“
Dense(num_classes, Softmax)
```

### Por que Transfer Learning?

1. **EficiÃªncia**: Aproveita features jÃ¡ aprendidas no ImageNet
2. **Menos dados**: NÃ£o precisa de milhÃµes de imagens para treinar
3. **Melhor performance**: Geralmente supera modelos treinados do zero
4. **Tempo**: Treino muito mais rÃ¡pido (minutos vs. dias)

### EfficientNetB0

- Arquitetura moderna baseada em **compound scaling**
- Balanceia profundidade, largura e resoluÃ§Ã£o
- Excelente trade-off entre acurÃ¡cia e eficiÃªncia
- ~5.3M parÃ¢metros

---

## ğŸ”§ TÃ©cnicas Utilizadas

### 1. Data Augmentation

Para aumentar a diversidade dos dados de treino:
- RotaÃ§Ã£o aleatÃ³ria (Â±20Â°)
- Deslocamento horizontal/vertical (Â±20%)
- Zoom aleatÃ³rio (Â±20%)
- Espelhamento horizontal
- Cisalhamento (shear)

### 2. Callbacks

- **EarlyStopping**: Para quando nÃ£o hÃ¡ melhoria (patience=10)
- **ModelCheckpoint**: Salva o melhor modelo
- **ReduceLROnPlateau**: Reduz learning rate quando estagna

### 3. RegularizaÃ§Ã£o

- **Dropout** (0.3 e 0.5) para prevenir overfitting
- **Data Augmentation** como regularizaÃ§Ã£o implÃ­cita

---

## ğŸš€ Como Executar

### PrÃ©-requisitos

- Python 3.12 (âš ï¸ **nÃ£o use Python 3.13!**)
- GPU NVIDIA (opcional, mas recomendado)
  - Com CUDA: treino ~100x mais rÃ¡pido
  - Sem GPU: treino em CPU (mais lento, mas funcional)

### 1. InstalaÃ§Ã£o das DependÃªncias

```powershell
# Criar ambiente virtual (recomendado)
python -m venv venv

# Ativar ambiente
.\venv\Scripts\Activate.ps1

# Instalar dependÃªncias
pip install -r requirements.txt
```

### 2. AnÃ¡lise ExploratÃ³ria dos Dados

```powershell
python 01_exploratory_analysis.py
```

**SaÃ­das:**
- `class_distribution.png`: GrÃ¡ficos de distribuiÃ§Ã£o de classes
- `sample_images.png`: Amostras de imagens do dataset

**AnÃ¡lises realizadas:**
- DistribuiÃ§Ã£o de imagens por conjunto (train/valid/test)
- DistribuiÃ§Ã£o de imagens por raÃ§a
- AnÃ¡lise de propriedades das imagens (dimensÃµes, tamanho)
- VerificaÃ§Ã£o de integridade dos dados

### 3. Treinamento do Modelo

```powershell
python 02_train_model.py
```

**SaÃ­das:**
- `models/dog_classifier_YYYYMMDD_HHMMSS.keras`: Modelo treinado
- `models/class_indices.json`: Mapeamento de classes
- `models/training_results.json`: MÃ©tricas de treinamento
- `training_history.png`: Curvas de treinamento

**Tempo estimado:**
- Com GPU: 10-30 minutos
- Sem GPU: 2-4 horas

**HiperparÃ¢metros:**
- Batch size: 32
- Learning rate: 0.001
- Ã‰pocas mÃ¡ximas: 50 (com early stopping)
- Image size: 224x224

### 4. AvaliaÃ§Ã£o e AnÃ¡lise de Erros

```powershell
python 03_evaluate_model.py
```

**SaÃ­das (em `results/`):**
- `confusion_matrix.png`: Matriz de confusÃ£o normalizada
- `error_examples.png`: Exemplos de classificaÃ§Ãµes incorretas
- `correct_examples.png`: Exemplos de prediÃ§Ãµes corretas
- `per_class_performance.png`: Performance por raÃ§a
- `classification_report.txt`: RelatÃ³rio detalhado

**AnÃ¡lises realizadas:**
- Matriz de confusÃ£o das principais raÃ§as
- Pares de confusÃ£o mais comuns
- Performance individual por raÃ§a
- VisualizaÃ§Ã£o de erros e acertos
- MÃ©tricas: Accuracy, Precision, Recall, F1-Score

---

## ğŸ“ˆ Resultados Esperados

### MÃ©tricas TÃ­picas

Com o dataset fornecido e a arquitetura implementada, espera-se:

- **AcurÃ¡cia (Top-1)**: 70-85%
- **AcurÃ¡cia (Top-5)**: 90-95%
- **Training time**: 10-30 min (GPU) / 2-4h (CPU)

### InterpretaÃ§Ã£o dos Resultados

#### ğŸ¯ Bons Resultados
- RaÃ§as muito distintas (ex: Chihuahua vs. Great Dane)
- RaÃ§as com caracterÃ­sticas Ãºnicas (ex: Dalmatian - manchas)

#### âš ï¸ Desafios Comuns
- RaÃ§as similares (ex: Golden Retriever vs. Labrador)
- Imagens com fundo complexo
- Diferentes Ã¢ngulos/poses
- VariaÃ§Ã£o intra-raÃ§a (cor, tamanho)

---

## ğŸ” AnÃ¡lise de Erros

### O que observar:

1. **RaÃ§as confundidas**: Quais pares sÃ£o mais confundidos?
   - Ex: Se confunde Husky com Malamute â†’ raÃ§as realmente similares
   
2. **Performance por raÃ§a**: Algumas raÃ§as sÃ£o mais fÃ¡ceis?
   - RaÃ§as Ãºnicas (DÃ¡lmata) tendem a ter melhor performance
   - RaÃ§as similares (Spaniels) tendem a ter mais erros

3. **ConfianÃ§a das prediÃ§Ãµes**: 
   - Alta confianÃ§a em erros â†’ modelo estÃ¡ "convicto" mas errado
   - Baixa confianÃ§a â†’ modelo estÃ¡ "em dÃºvida"

4. **Top-5 Accuracy**: 
   - Se Top-5 >> Top-1 â†’ modelo considera mÃºltiplas raÃ§as plausÃ­veis
   - Ãštil para aplicaÃ§Ãµes com "sugestÃµes"

### PossÃ­veis ObservaÃ§Ãµes

Se vocÃª observar que:
- **RaÃ§as grandes sÃ£o confundidas entre si**: Modelo pode estar identificando tamanho em vez de caracterÃ­sticas faciais
- **Cores similares causam erros**: Textura/cor pode dominar sobre forma
- **Puppies vs Adults**: Idade pode confundir o modelo

Essas observaÃ§Ãµes **nÃ£o sÃ£o problemas**, mas **insights valiosos** sobre o que o modelo aprendeu!

---

## ğŸ§  Conceitos de ComputaÃ§Ã£o NumÃ©rica Aplicados

### 1. ConvoluÃ§Ã£o (Convolutional Layers)

A operaÃ§Ã£o de convoluÃ§Ã£o Ã© uma **operaÃ§Ã£o matemÃ¡tica** entre uma imagem e um filtro (kernel):

$$
(f * g)(x, y) = \sum_{i=-k}^{k} \sum_{j=-k}^{k} f(i, j) \cdot g(x-i, y-j)
$$

- **Filtros**: Detectam features (bordas, texturas, formas)
- **Compartilhamento de pesos**: Mesmos filtros em toda imagem
- **InvariÃ¢ncia a translaÃ§Ã£o**: Detecta features independente da posiÃ§Ã£o

### 2. Backpropagation e Gradiente Descendente

O treinamento usa **gradiente descendente** para minimizar a funÃ§Ã£o de perda:

$$
\theta_{t+1} = \theta_t - \eta \nabla_\theta L(\theta_t)
$$

Onde:
- $\theta$: ParÃ¢metros (pesos) da rede
- $\eta$: Learning rate
- $\nabla_\theta L$: Gradiente da funÃ§Ã£o de perda
- $L$: Loss function (categorical cross-entropy)

**Backpropagation** usa a **regra da cadeia** para calcular gradientes eficientemente atravÃ©s das camadas.

### 3. Softmax e Cross-Entropy

A camada final usa **softmax** para converter logits em probabilidades:

$$
P(y=k|x) = \frac{e^{z_k}}{\sum_{j=1}^{K} e^{z_j}}
$$

A **categorical cross-entropy loss** mede a diferenÃ§a entre prediÃ§Ã£o e verdade:

$$
L = -\sum_{i=1}^{K} y_i \log(\hat{y}_i)
$$

### 4. NormalizaÃ§Ã£o Batch

EfficientNet usa **Batch Normalization** para estabilizar treinamento:

$$
\hat{x} = \frac{x - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}}
$$

BenefÃ­cios:
- Acelera convergÃªncia
- Permite learning rates maiores
- RegularizaÃ§Ã£o implÃ­cita

### 5. Pooling

**Global Average Pooling** reduz dimensÃµes espaciais:

$$
GAP(X) = \frac{1}{H \times W} \sum_{i=1}^{H} \sum_{j=1}^{W} X_{i,j}
$$

Vantagens:
- Reduz parÃ¢metros
- InvariÃ¢ncia a translaÃ§Ã£o
- Reduz overfitting

---

## ğŸ“š Estrutura do CÃ³digo

```
.
â”œâ”€â”€ 01_exploratory_analysis.py    # AnÃ¡lise exploratÃ³ria dos dados
â”œâ”€â”€ 02_train_model.py             # Treinamento do modelo
â”œâ”€â”€ 03_evaluate_model.py          # AvaliaÃ§Ã£o e anÃ¡lise de erros
â”œâ”€â”€ requirements.txt              # DependÃªncias do projeto
â”œâ”€â”€ README.md                     # Este arquivo
â”œâ”€â”€ archive/                      # Dataset (nÃ£o versionado)
â”‚   â”œâ”€â”€ dogs.csv
â”‚   â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ valid/
â”‚   â””â”€â”€ test/
â”œâ”€â”€ models/                       # Modelos treinados (gerado)
â”‚   â”œâ”€â”€ dog_classifier_*.keras
â”‚   â”œâ”€â”€ class_indices.json
â”‚   â””â”€â”€ training_results.json
â””â”€â”€ results/                      # Resultados da avaliaÃ§Ã£o (gerado)
    â”œâ”€â”€ confusion_matrix.png
    â”œâ”€â”€ error_examples.png
    â”œâ”€â”€ correct_examples.png
    â”œâ”€â”€ per_class_performance.png
    â””â”€â”€ classification_report.txt
```

---

## ğŸ’¡ Dicas e Troubleshooting

### GPU nÃ£o detectada

Se vocÃª tem GPU NVIDIA mas TensorFlow nÃ£o detecta:

```powershell
# Verifica CUDA
nvidia-smi

# Instala CUDA Toolkit e cuDNN (se necessÃ¡rio)
# Baixar de: https://developer.nvidia.com/cuda-downloads

# Verifica TensorFlow com GPU
python -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"
```

### MemÃ³ria insuficiente (GPU)

Se ocorrer `Out of Memory`:

```python
# Em 02_train_model.py, reduza o BATCH_SIZE
BATCH_SIZE = 16  # ou 8
```

### Treino muito lento (CPU)

Se nÃ£o tiver GPU e quiser resultados mais rÃ¡pidos:

```python
# Reduza EPOCHS e use menos dados
EPOCHS = 10

# Ou use um subset do dataset
train_df = train_df.sample(frac=0.3)  # 30% dos dados
```

### Erros de importaÃ§Ã£o

```powershell
# Reinstala TensorFlow
pip uninstall tensorflow keras
pip install tensorflow==2.15.0
```

---

## ğŸ“ RelatÃ³rio da ExperimentaÃ§Ã£o

### Perguntas para Responder na ApresentaÃ§Ã£o

1. **Qual foi a acurÃ¡cia final no conjunto de teste?**
   - Responda com nÃºmeros exatos
   - Compare Top-1 vs Top-5

2. **Quais raÃ§as o modelo confunde mais?**
   - Mostre os pares de confusÃ£o mais comuns
   - Explique por que (caracterÃ­sticas similares?)

3. **O modelo estÃ¡ aprendendo caracterÃ­sticas ou decorando?**
   - Compare acurÃ¡cia treino vs validaÃ§Ã£o
   - Se treino >> validaÃ§Ã£o â†’ overfitting
   - Se ambos altos â†’ generalizaÃ§Ã£o boa

4. **Quais raÃ§as tÃªm melhor/pior performance?**
   - Liste top 5 melhores e piores
   - Explique possÃ­veis motivos

5. **O que o modelo aprendeu?**
   - EstÃ¡ identificando raÃ§as ou outros padrÃµes?
   - Ex: cor, tamanho, background?

6. **Data Augmentation ajudou?**
   - Compare com/sem (se tiver tempo)
   - Observe curvas de treino/validaÃ§Ã£o

### Estrutura Sugerida da ApresentaÃ§Ã£o (10-15 min)

1. **IntroduÃ§Ã£o** (2 min)
   - Problema: ClassificaÃ§Ã£o de raÃ§as
   - Dataset: 70+ raÃ§as, ~9000 imagens

2. **Metodologia** (4 min)
   - Transfer Learning com EfficientNetB0
   - Data Augmentation
   - Arquitetura do modelo

3. **Resultados** (5 min)
   - MÃ©tricas gerais
   - Matriz de confusÃ£o
   - Exemplos de erros e acertos
   - Performance por raÃ§a

4. **AnÃ¡lise e DiscussÃ£o** (3 min)
   - O que funcionou bem
   - Desafios encontrados
   - PossÃ­veis melhorias

5. **ConclusÃ£o** (1 min)
   - Resumo dos resultados
   - Aprendizados

---

## ğŸš€ PossÃ­veis ExtensÃµes

Se quiser ir alÃ©m:

1. **Fine-tuning**: Descongelar Ãºltimas camadas do EfficientNet
2. **Ensemble**: Treinar mÃºltiplos modelos e combinar
3. **Outras arquiteturas**: ResNet50, VGG16, EfficientNetB3
4. **Grad-CAM**: Visualizar o que o modelo "olha"
5. **Test-Time Augmentation**: MÃºltiplas versÃµes da imagem no teste
6. **Class Balancing**: Lidar com classes desbalanceadas

---

## ğŸ“– ReferÃªncias

- **EfficientNet**: Tan & Le (2019) - "EfficientNet: Rethinking Model Scaling for CNNs"
- **Transfer Learning**: Yosinski et al. (2014) - "How transferable are features in deep neural networks?"
- **Data Augmentation**: Shorten & Khoshgoftaar (2019) - "A survey on Image Data Augmentation"
- **TensorFlow Documentation**: https://www.tensorflow.org/
- **Keras Applications**: https://keras.io/api/applications/

---

## âœ… Checklist para a ApresentaÃ§Ã£o

- [ ] Executei anÃ¡lise exploratÃ³ria
- [ ] Treinei o modelo atÃ© convergÃªncia
- [ ] Avaliei no conjunto de teste
- [ ] Gerei todas as visualizaÃ§Ãµes
- [ ] Analisei os erros mais comuns
- [ ] Entendi o que o modelo aprendeu
- [ ] Preparei slides com resultados
- [ ] Testei cÃ³digo antes da apresentaÃ§Ã£o

---

## ğŸ“ Notas Finais

Este projeto demonstra:
- âœ… AplicaÃ§Ã£o prÃ¡tica de CNNs
- âœ… Transfer Learning eficiente
- âœ… Boas prÃ¡ticas de Machine Learning
- âœ… AnÃ¡lise crÃ­tica de resultados
- âœ… DocumentaÃ§Ã£o completa

**Boa sorte na apresentaÃ§Ã£o! ğŸ‰**

---

## ğŸ“§ Contato

**Autor:** Luis  
**Disciplina:** ComputaÃ§Ã£o SimbÃ³lica e NumÃ©rica (CSN)  
**Data:** 26/11/2025

